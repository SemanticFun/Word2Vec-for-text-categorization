{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "configuration = 1    # possible values are: 1, 2, 3\n",
    "\n",
    "###\n",
    "# configuration=1 --> P1: tokenization, stop word removal\n",
    "# configuration=2 --> P2: tokenization, stop word removal, lemmatization\n",
    "# configuration=3 --> P3: tokenization, stop word removal, lemmatization, keyphrase extraction\n",
    "###\n",
    "\n",
    "folder=\"configuration_\"+str(configuration)\n",
    "\n",
    "if configuration == 1:\n",
    "    lemmatization=False\n",
    "    bigram=False\n",
    "elif configuration == 2:\n",
    "    lemmatization=True\n",
    "    bigram=False\n",
    "elif configuration == 3:\n",
    "    lemmatization=True\n",
    "    bigram=True\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "if not os.path.exists(folder+\"/models\"):\n",
    "    os.makedirs(folder+\"/models\")\n",
    "if not os.path.exists(folder+\"/simple\"):\n",
    "    os.makedirs(folder+\"/simple\")\n",
    "if not os.path.exists(folder+\"/tfidf\"):\n",
    "    os.makedirs(folder+\"/tfidf\")\n",
    "if not os.path.exists(folder+\"/simple/csv\"):\n",
    "    os.makedirs(folder+\"/simple/csv\")\n",
    "if not os.path.exists(folder+\"/tfidf/csv\"):\n",
    "    os.makedirs(folder+\"/tfidf/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import sql, connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 connection: <connection object at 0x000001C7A462BD00; dsn: 'user=crime_news_ro password=xxx dbname=crime_news host=localhost port=5532', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "#connection_string=\"dbname='crime_news' user='crime_news_ro' host='localhost' port=5532 password='**********'\"\n",
    "conn = connect(\n",
    "                dbname='crime_news', \n",
    "                host='localhost', \n",
    "                port=5532,\n",
    "                user='crime_news_ro', \n",
    "                password='**********'\n",
    "            )\n",
    "\n",
    "print(\"psycopg2 connection:\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import gensim, nltk, re\n",
    "import spacy\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import KeyedVectors\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from multi_rake import Rake\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetch data from table 'news'\n",
    "\n",
    "We use psycopg2 to fetch all the records of table 'news' and create a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_names(conn, table):\n",
    "\n",
    "    # declare an empty list for the column names\n",
    "    columns = []\n",
    "\n",
    "    # declare cursor objects from the connection    \n",
    "    col_cursor = conn.cursor()\n",
    "\n",
    "    # concatenate string for query to get column names\n",
    "    # SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = 'some_table';\n",
    "    sql_str = \"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE \"\n",
    "    sql_str += \"table_name = '{}';\".format( table )\n",
    "\n",
    "    try:\n",
    "        sql_object = sql.SQL(\n",
    "            # pass SQL statement to sql.SQL() method\n",
    "            sql_str\n",
    "        ).format(\n",
    "            # pass the identifier to the Identifier() method\n",
    "            sql.Identifier( table )\n",
    "        )\n",
    "\n",
    "        # execute the SQL string to get list with col names in a tuple\n",
    "        col_cursor.execute( sql_object )\n",
    "\n",
    "        # get the tuple element from the liast\n",
    "        col_names = ( col_cursor.fetchall() )\n",
    "\n",
    "        # iterate list of tuples and grab first element\n",
    "        for tup in col_names:\n",
    "            print(tup)\n",
    "            # append the col name string to the list\n",
    "            columns += [ tup[0] ]\n",
    "\n",
    "        # close the cursor object to prevent memory leaks\n",
    "        col_cursor.close()\n",
    "\n",
    "    except Exception as err:\n",
    "        print (\"get_columns_names ERROR:\", err)\n",
    "\n",
    "    # return the list of column names\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(conn, table):\n",
    "    print('start')\n",
    "    # declare cursor objects from the connection    \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # concatenate string for query to get column names\n",
    "    # SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = 'some_table';\n",
    "    sql_str = \"SELECT * FROM crime_news.{} ;\".format( table )\n",
    "\n",
    "    try:\n",
    "        sql_object = sql.SQL(\n",
    "            # pass SQL statement to sql.SQL() method\n",
    "            sql_str\n",
    "        ).format(\n",
    "            # pass the identifier to the Identifier() method\n",
    "            sql.Identifier(table)\n",
    "        )\n",
    "\n",
    "        # execute the SQL string to get list with col names in a tuple\n",
    "        cursor.execute( sql_object )\n",
    "\n",
    "        # get the tuple element from the liast\n",
    "        records = cursor.fetchall()\n",
    "        print('end')\n",
    "\n",
    "    except Exception as err:\n",
    "        print (\"get_columns_names ERROR:\", err)\n",
    "\n",
    "    # return the list of column names\n",
    "    return np.array(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_table(conn, table):\n",
    "    # get columns of table\n",
    "    columns = get_columns_names(conn, table)\n",
    "        \n",
    "    # get data of table\n",
    "    data = get_data(conn, table)\n",
    "    \n",
    "    # get the frame\n",
    "    frame = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('url',)\n",
      "('title',)\n",
      "('description',)\n",
      "('text',)\n",
      "('municipality',)\n",
      "('area',)\n",
      "('address',)\n",
      "('date',)\n",
      "('time',)\n",
      "('geom',)\n",
      "('object',)\n",
      "('newspaper',)\n",
      "('tag',)\n",
      "('is_general',)\n",
      "('date_event',)\n",
      "('new_tag',)\n",
      "start\n",
      "end\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>municipality</th>\n",
       "      <th>area</th>\n",
       "      <th>address</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>geom</th>\n",
       "      <th>object</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>tag</th>\n",
       "      <th>is_general</th>\n",
       "      <th>date_event</th>\n",
       "      <th>new_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Sassuolo. Banda del tombino in azione vetrine ...</td>\n",
       "      <td>Ancora furti e vandalismi in città. Nelle ore ...</td>\n",
       "      <td>SASSUOLO. Ancora furti e vandalismi in città. ...</td>\n",
       "      <td>sassuolo</td>\n",
       "      <td></td>\n",
       "      <td>via radici</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0101000020E61000001F97827F5B91254022BAB1EABD45...</td>\n",
       "      <td>vandalismi</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Catturano un ladro: «Sono un podista» Agenti a...</td>\n",
       "      <td>I quattro ammanettarono l’uomo nelle vicinanze...</td>\n",
       "      <td>Serena Arbizzi Sta entrando nel vivo il proces...</td>\n",
       "      <td>modena</td>\n",
       "      <td>accademia militare</td>\n",
       "      <td></td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>«sono</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>L’encomio di Mattarella per gli agenti .</td>\n",
       "      <td></td>\n",
       "      <td>Un arresto per evasione, un altro per furto fu...</td>\n",
       "      <td>modena</td>\n",
       "      <td>accademia militare</td>\n",
       "      <td></td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Rapinarono un portavalori al Grandemilia di Mo...</td>\n",
       "      <td>Due in manette: uno è stato preso a Napoli a b...</td>\n",
       "      <td>Serena Arbizzi Era a Napoli, sulla nave. Stava...</td>\n",
       "      <td>modena</td>\n",
       "      <td>accademia militare</td>\n",
       "      <td></td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Emilia Romagna. A scuola i figli dei medici? «...</td>\n",
       "      <td>La Regione ha convenuto  di inviare una richie...</td>\n",
       "      <td>Paola Ducci Per ora è certo che da oggi in cla...</td>\n",
       "      <td>modena</td>\n",
       "      <td>accademia militare</td>\n",
       "      <td></td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>http://www.modenatoday.it/video/trovata-arma-a...</td>\n",
       "      <td>Agguato al primario di Cardiologia, ritrovata ...</td>\n",
       "      <td>Indagini a tutto tondo di Carabinieri e Procur...</td>\n",
       "      <td>Indagini a tutto tondo di Carabinieri e Procur...</td>\n",
       "      <td>marano</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>12:38:00</td>\n",
       "      <td>0101000020E61000005820D50B997E2640EA31DB5F8732...</td>\n",
       "      <td>soda</td>\n",
       "      <td>ModenaToday</td>\n",
       "      <td>aggressione</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17528</th>\n",
       "      <td>http://gazzettadimodena.gelocal.it/modena/cron...</td>\n",
       "      <td>Sassuolo, anziana va dal medico e i ladri le s...</td>\n",
       "      <td>Hanno smurato la porta d’ingresso dell’abitazi...</td>\n",
       "      <td>SASSUOLO. Continuano con incredibile frequenza...</td>\n",
       "      <td>sassuolo</td>\n",
       "      <td></td>\n",
       "      <td>via pergolesi rometta rometta</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0101000020E610000033593739D7932540E7E6768AB043...</td>\n",
       "      <td>svaligiano</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Boom di furti in casa a Modena, comitato in pi...</td>\n",
       "      <td>Domani mattina il presidio dei residenti del V...</td>\n",
       "      <td>MODENA. Mentre parla, indica le inferriate al ...</td>\n",
       "      <td>modena</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0101000020E61000008B451D67E4D92540662E7079AC52...</td>\n",
       "      <td>casa</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>http://www.modenatoday.it/cronaca/sequestri-pr...</td>\n",
       "      <td>Finanza al mercato di Maranello, sequestrati 3...</td>\n",
       "      <td>Ambulante straniero vendeva merce priva dei re...</td>\n",
       "      <td>La Guardia di finanza prosegue nella lotta ai...</td>\n",
       "      <td>Maranello</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>15:02:00</td>\n",
       "      <td>0101000020E61000004F1432A193BB25404E6B894B4443...</td>\n",
       "      <td>prodotti</td>\n",
       "      <td>ModenaToday</td>\n",
       "      <td>sequestro</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Maturità a Modena, arriva l’orale Ma a preoccu...</td>\n",
       "      <td>Il dirigente dell’Ufficio scolastico Silvia Me...</td>\n",
       "      <td>MODENA E’ stato il sorteggio della lettera del...</td>\n",
       "      <td>modena</td>\n",
       "      <td>accademia militare</td>\n",
       "      <td></td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>furto</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17532 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "1      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "2      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "3      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "4      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "...                                                  ...   \n",
       "17527  http://www.modenatoday.it/video/trovata-arma-a...   \n",
       "17528  http://gazzettadimodena.gelocal.it/modena/cron...   \n",
       "17529  https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "17530  http://www.modenatoday.it/cronaca/sequestri-pr...   \n",
       "17531  https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Sassuolo. Banda del tombino in azione vetrine ...   \n",
       "1      Catturano un ladro: «Sono un podista» Agenti a...   \n",
       "2               L’encomio di Mattarella per gli agenti .   \n",
       "3      Rapinarono un portavalori al Grandemilia di Mo...   \n",
       "4      Emilia Romagna. A scuola i figli dei medici? «...   \n",
       "...                                                  ...   \n",
       "17527  Agguato al primario di Cardiologia, ritrovata ...   \n",
       "17528  Sassuolo, anziana va dal medico e i ladri le s...   \n",
       "17529  Boom di furti in casa a Modena, comitato in pi...   \n",
       "17530  Finanza al mercato di Maranello, sequestrati 3...   \n",
       "17531  Maturità a Modena, arriva l’orale Ma a preoccu...   \n",
       "\n",
       "                                             description  \\\n",
       "0      Ancora furti e vandalismi in città. Nelle ore ...   \n",
       "1      I quattro ammanettarono l’uomo nelle vicinanze...   \n",
       "2                                                          \n",
       "3      Due in manette: uno è stato preso a Napoli a b...   \n",
       "4      La Regione ha convenuto  di inviare una richie...   \n",
       "...                                                  ...   \n",
       "17527  Indagini a tutto tondo di Carabinieri e Procur...   \n",
       "17528  Hanno smurato la porta d’ingresso dell’abitazi...   \n",
       "17529  Domani mattina il presidio dei residenti del V...   \n",
       "17530  Ambulante straniero vendeva merce priva dei re...   \n",
       "17531  Il dirigente dell’Ufficio scolastico Silvia Me...   \n",
       "\n",
       "                                                    text municipality  \\\n",
       "0      SASSUOLO. Ancora furti e vandalismi in città. ...     sassuolo   \n",
       "1      Serena Arbizzi Sta entrando nel vivo il proces...       modena   \n",
       "2      Un arresto per evasione, un altro per furto fu...       modena   \n",
       "3      Serena Arbizzi Era a Napoli, sulla nave. Stava...       modena   \n",
       "4      Paola Ducci Per ora è certo che da oggi in cla...       modena   \n",
       "...                                                  ...          ...   \n",
       "17527  Indagini a tutto tondo di Carabinieri e Procur...       marano   \n",
       "17528  SASSUOLO. Continuano con incredibile frequenza...     sassuolo   \n",
       "17529  MODENA. Mentre parla, indica le inferriate al ...       modena   \n",
       "17530   La Guardia di finanza prosegue nella lotta ai...    Maranello   \n",
       "17531  MODENA E’ stato il sorteggio della lettera del...       modena   \n",
       "\n",
       "                     area                         address        date  \\\n",
       "0                                             via radici   2021-06-25   \n",
       "1      accademia militare                                  2021-06-24   \n",
       "2      accademia militare                                  2021-06-24   \n",
       "3      accademia militare                                  2021-09-01   \n",
       "4      accademia militare                                  2021-03-08   \n",
       "...                   ...                             ...         ...   \n",
       "17527                                                      2016-11-14   \n",
       "17528                      via pergolesi rometta rometta   2017-01-31   \n",
       "17529                                                None  2020-01-01   \n",
       "17530                                                      2014-09-18   \n",
       "17531  accademia militare                                  2020-06-16   \n",
       "\n",
       "           time                                               geom  \\\n",
       "0      01:00:00  0101000020E61000001F97827F5B91254022BAB1EABD45...   \n",
       "1      01:00:00                                               None   \n",
       "2      01:00:00                                               None   \n",
       "3      01:00:00                                               None   \n",
       "4      01:00:00                                               None   \n",
       "...         ...                                                ...   \n",
       "17527  12:38:00  0101000020E61000005820D50B997E2640EA31DB5F8732...   \n",
       "17528  01:00:00  0101000020E610000033593739D7932540E7E6768AB043...   \n",
       "17529  01:00:00  0101000020E61000008B451D67E4D92540662E7079AC52...   \n",
       "17530  15:02:00  0101000020E61000004F1432A193BB25404E6B894B4443...   \n",
       "17531  01:00:00                                               None   \n",
       "\n",
       "           object           newspaper          tag is_general  date_event  \\\n",
       "0      vandalismi  Gazzetta di Modena        furto          0        None   \n",
       "1           «sono  Gazzetta di Modena        furto          0        None   \n",
       "2                  Gazzetta di Modena        furto          0        None   \n",
       "3                  Gazzetta di Modena        furto          0        None   \n",
       "4                  Gazzetta di Modena        furto          0  2021-03-08   \n",
       "...           ...                 ...          ...        ...         ...   \n",
       "17527        soda         ModenaToday  aggressione          0  2016-11-11   \n",
       "17528  svaligiano  Gazzetta di Modena        furto          0  2017-01-31   \n",
       "17529        casa  Gazzetta di Modena        furto          0  2020-01-01   \n",
       "17530    prodotti         ModenaToday    sequestro          0  2014-09-18   \n",
       "17531              Gazzetta di Modena        furto          0  2020-05-16   \n",
       "\n",
       "      new_tag  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "...       ...  \n",
       "17527    None  \n",
       "17528   furto  \n",
       "17529   furto  \n",
       "17530    None  \n",
       "17531   furto  \n",
       "\n",
       "[17532 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_dataframe_from_table(conn, 'news')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17504, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gazzetta di Modena    11604\n",
       "ModenaToday            5900\n",
       "Name: newspaper, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['newspaper'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "\n",
    "The preprocessing step includes lemmatization, stop words removal and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to download the file \"italian.pickle\"\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Convert a review to a list of words. Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = (re.sub(\"[^a-zA-Z]\",\" \", review)).lower()\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(nltk.corpus.stopwords.words('italian'))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    Split review into list of sentences where each sentence is a list of words.\n",
    "    Removal of stop words is optional.\n",
    "    \"\"\"\n",
    "    # use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    # each sentence is furthermore split into words\n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences += review_to_wordlist(raw_sentence, remove_stopwords)\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['url', 'title', 'text', 'newspaper', 'date', 'time', 'tag']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#if lemmatization==False and bigram==False:\n",
    "if configuration == 1:\n",
    "    data.insert(3, 'preprocessed', data['text'].apply(lambda article: review_to_sentences(article, tokenizer, remove_stopwords=True)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocPreprocess(object):\n",
    "\n",
    "    def __init__(self, nlp, stop_words, docs, #labels, \n",
    "                     build_bi=False, min_count=3, threshold=5, \n",
    "                     allowed_postags=['ADV', 'VERB', 'ADJ', 'NOUN', 'PROPN', 'NUM']):\n",
    "\n",
    "        self.nlp = nlp\n",
    "        self.stop_words = stop_words\n",
    "        self.docs = docs\n",
    "        # self.labels = labels\n",
    "        self.doc_ids = np.arange(len(docs))\n",
    "        self.simple_doc_tokens = [gensim.utils.simple_preprocess(doc, deacc=True) for doc in self.docs]\n",
    "\n",
    "        if build_bi:\n",
    "            self.bi_detector = self.build_bi_detect(self.simple_doc_tokens, min_count=min_count, threshold=threshold)\n",
    "            self.new_docs = self.make_bigram_doc(self.bi_detector, self.simple_doc_tokens)\n",
    "            \n",
    "            rake = Rake(min_chars=3,\n",
    "                    max_words=3,\n",
    "                    min_freq=2,\n",
    "                    language_code='it',\n",
    "                    stopwords=stop_words)\n",
    "                    #punctuations=',;.:-_()\\'!?\"')\n",
    "            self.keyphrase = self.docs.apply(lambda text: rake.apply(text, text_for_stopwords=None))\n",
    "            self.new_keyphrases = [self.make_keyphrase_doc(doc) for doc in range(len(self.new_docs))]\n",
    "        else:\n",
    "            self.new_docs = self.make_simple_doc(self.simple_doc_tokens)\n",
    "        self.doc_words = [self.lemmatize(doc, allowed_postags=allowed_postags) for doc in self.new_docs]\n",
    "        self.tagdocs = [TaggedDocument(words=words, tags=[tag]) for words, tag in zip(self.doc_words, self.doc_ids)]\n",
    "        \n",
    "        if build_bi:\n",
    "            [self.doc_words[doc].extend(self.new_keyphrases[doc]) for doc in range(len(self.new_docs))]\n",
    "        \n",
    "    def build_bi_detect(self, simple_doc_tokens, min_count, threshold):\n",
    "        # nostopword_doc_tokens = [token for token in simple_doc_tokens if (token not in self.stop_words)]\n",
    "        nostopword_doc_tokens = []\n",
    "        for array in simple_doc_tokens:\n",
    "            new_array=[]\n",
    "            for element in array:\n",
    "                if element not in self.stop_words:\n",
    "                    new_array.append(element)\n",
    "            nostopword_doc_tokens.append(new_array)\n",
    "        \n",
    "        bi_ = gensim.models.phrases.Phrases(nostopword_doc_tokens, min_count=min_count, threshold=threshold, scoring='default')\n",
    "        bi_detector = gensim.models.phrases.Phraser(bi_)  # wrapper enhance efficiency\n",
    "        return bi_detector\n",
    "\n",
    "    def make_keyphrase_doc(self, doc):\n",
    "        keyphrases = []\n",
    "        keys = \"\"\n",
    "        for k in self.keyphrase[doc]:\n",
    "            keys = keys + \" \" + k[0].replace(' ', '_')  # concatenate back to a sentence\n",
    "        keyphrases.append(keys)\n",
    "        return keyphrases\n",
    "    \n",
    "    def make_bigram_doc(self, bi_detector, simple_doc_tokens):\n",
    "        #nostopword_doc_tokens = [token for token in simple_doc_tokens if (token not in self.stop_words)]\n",
    "        bi_doc_tokens = [bi_detector[doc_tokens] for doc_tokens in simple_doc_tokens]\n",
    "        bi_docs = []\n",
    "        for bi_tokens in bi_doc_tokens:\n",
    "            bi_doc = \" \".join(bi_tokens)  # concatenate back to a sentence\n",
    "            bi_docs.append(bi_doc)\n",
    "        return bi_docs\n",
    "\n",
    "    def make_simple_doc(self, simple_doc_tokens):\n",
    "        simple_docs = []\n",
    "        for doc_tokens in simple_doc_tokens:\n",
    "            simple = \" \".join(doc_tokens)  # concatenate back to a sentence\n",
    "            simple_docs.append(simple)\n",
    "        return simple_docs\n",
    "\n",
    "    def lemmatize(self, doc, allowed_postags):\n",
    "        doc = self.nlp(doc)\n",
    "        tokens = [token.lemma_ for token in doc if (token.text not in self.stop_words)]\n",
    "                  #(token.pos_ in allowed_postags) and (token.text not in self.stop_words)]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the instructions at https://spacy.io/usage for downloading\n",
    "\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "stop_words = nltk.corpus.stopwords.words('italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if configuration == 2:\n",
    "    all_docs = DocPreprocess(nlp, stop_words, data['text'])\n",
    "    data.insert(3, \"preprocessed\", all_docs.doc_words, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Keyphrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if configuration == 3:\n",
    "    all_docs = DocPreprocess(nlp, stop_words, data['text'], True)\n",
    "    data.insert(3, \"preprocessed\", all_docs.doc_words, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [sassuolo, ancorare, furto, vandalismo, citta,...\n",
       "1        [sereno, arbizzi, entrare, vivere, processare,...\n",
       "2        [arrestare, evasione, altro, furto, fuori, ora...\n",
       "3        [sereno, arbizzi, napoli, nave, partire, volto...\n",
       "4        [paola, ducci, orare, certo, oggi, classe, pre...\n",
       "                               ...                        \n",
       "17499    [indagine, tondo, carabiniere, procurare, chiu...\n",
       "17500    [sassuolo, continuare, incredibile, frequenza,...\n",
       "17501    [modena, mentre, parlare, indire, inferriata, ...\n",
       "17502    [guardia, finanza, proseguire, lottare, produr...\n",
       "17503    [modena, stare, sorteggiare, lettera, alfabeto...\n",
       "Name: preprocessed, Length: 17504, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete those articles whose word list is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for index, sent in enumerate(data['preprocessed']):\n",
    "    if len(sent) == 0:\n",
    "        indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17455, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(indexes, axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Sassuolo. Banda del tombino in azione vetrine ...</td>\n",
       "      <td>SASSUOLO. Ancora furti e vandalismi in città. ...</td>\n",
       "      <td>[sassuolo, ancorare, furto, vandalismo, citta,...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Catturano un ladro: «Sono un podista» Agenti a...</td>\n",
       "      <td>Serena Arbizzi Sta entrando nel vivo il proces...</td>\n",
       "      <td>[sereno, arbizzi, entrare, vivere, processare,...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>L’encomio di Mattarella per gli agenti .</td>\n",
       "      <td>Un arresto per evasione, un altro per furto fu...</td>\n",
       "      <td>[arrestare, evasione, altro, furto, fuori, ora...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Rapinarono un portavalori al Grandemilia di Mo...</td>\n",
       "      <td>Serena Arbizzi Era a Napoli, sulla nave. Stava...</td>\n",
       "      <td>[sereno, arbizzi, napoli, nave, partire, volto...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Emilia Romagna. A scuola i figli dei medici? «...</td>\n",
       "      <td>Paola Ducci Per ora è certo che da oggi in cla...</td>\n",
       "      <td>[paola, ducci, orare, certo, oggi, classe, pre...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17450</th>\n",
       "      <td>http://www.modenatoday.it/video/trovata-arma-a...</td>\n",
       "      <td>Agguato al primario di Cardiologia, ritrovata ...</td>\n",
       "      <td>Indagini a tutto tondo di Carabinieri e Procur...</td>\n",
       "      <td>[indagine, tondo, carabiniere, procurare, chiu...</td>\n",
       "      <td>ModenaToday</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>12:38:00</td>\n",
       "      <td>aggressione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17451</th>\n",
       "      <td>http://gazzettadimodena.gelocal.it/modena/cron...</td>\n",
       "      <td>Sassuolo, anziana va dal medico e i ladri le s...</td>\n",
       "      <td>SASSUOLO. Continuano con incredibile frequenza...</td>\n",
       "      <td>[sassuolo, continuare, incredibile, frequenza,...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17452</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Boom di furti in casa a Modena, comitato in pi...</td>\n",
       "      <td>MODENA. Mentre parla, indica le inferriate al ...</td>\n",
       "      <td>[modena, mentre, parlare, indire, inferriata, ...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17453</th>\n",
       "      <td>http://www.modenatoday.it/cronaca/sequestri-pr...</td>\n",
       "      <td>Finanza al mercato di Maranello, sequestrati 3...</td>\n",
       "      <td>La Guardia di finanza prosegue nella lotta ai...</td>\n",
       "      <td>[guardia, finanza, proseguire, lottare, produr...</td>\n",
       "      <td>ModenaToday</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>15:02:00</td>\n",
       "      <td>sequestro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17454</th>\n",
       "      <td>https://gazzettadimodena.gelocal.it/modena/cro...</td>\n",
       "      <td>Maturità a Modena, arriva l’orale Ma a preoccu...</td>\n",
       "      <td>MODENA E’ stato il sorteggio della lettera del...</td>\n",
       "      <td>[modena, stare, sorteggiare, lettera, alfabeto...</td>\n",
       "      <td>Gazzetta di Modena</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>furto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17455 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "1      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "2      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "3      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "4      https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "...                                                  ...   \n",
       "17450  http://www.modenatoday.it/video/trovata-arma-a...   \n",
       "17451  http://gazzettadimodena.gelocal.it/modena/cron...   \n",
       "17452  https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "17453  http://www.modenatoday.it/cronaca/sequestri-pr...   \n",
       "17454  https://gazzettadimodena.gelocal.it/modena/cro...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Sassuolo. Banda del tombino in azione vetrine ...   \n",
       "1      Catturano un ladro: «Sono un podista» Agenti a...   \n",
       "2               L’encomio di Mattarella per gli agenti .   \n",
       "3      Rapinarono un portavalori al Grandemilia di Mo...   \n",
       "4      Emilia Romagna. A scuola i figli dei medici? «...   \n",
       "...                                                  ...   \n",
       "17450  Agguato al primario di Cardiologia, ritrovata ...   \n",
       "17451  Sassuolo, anziana va dal medico e i ladri le s...   \n",
       "17452  Boom di furti in casa a Modena, comitato in pi...   \n",
       "17453  Finanza al mercato di Maranello, sequestrati 3...   \n",
       "17454  Maturità a Modena, arriva l’orale Ma a preoccu...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      SASSUOLO. Ancora furti e vandalismi in città. ...   \n",
       "1      Serena Arbizzi Sta entrando nel vivo il proces...   \n",
       "2      Un arresto per evasione, un altro per furto fu...   \n",
       "3      Serena Arbizzi Era a Napoli, sulla nave. Stava...   \n",
       "4      Paola Ducci Per ora è certo che da oggi in cla...   \n",
       "...                                                  ...   \n",
       "17450  Indagini a tutto tondo di Carabinieri e Procur...   \n",
       "17451  SASSUOLO. Continuano con incredibile frequenza...   \n",
       "17452  MODENA. Mentre parla, indica le inferriate al ...   \n",
       "17453   La Guardia di finanza prosegue nella lotta ai...   \n",
       "17454  MODENA E’ stato il sorteggio della lettera del...   \n",
       "\n",
       "                                            preprocessed           newspaper  \\\n",
       "0      [sassuolo, ancorare, furto, vandalismo, citta,...  Gazzetta di Modena   \n",
       "1      [sereno, arbizzi, entrare, vivere, processare,...  Gazzetta di Modena   \n",
       "2      [arrestare, evasione, altro, furto, fuori, ora...  Gazzetta di Modena   \n",
       "3      [sereno, arbizzi, napoli, nave, partire, volto...  Gazzetta di Modena   \n",
       "4      [paola, ducci, orare, certo, oggi, classe, pre...  Gazzetta di Modena   \n",
       "...                                                  ...                 ...   \n",
       "17450  [indagine, tondo, carabiniere, procurare, chiu...         ModenaToday   \n",
       "17451  [sassuolo, continuare, incredibile, frequenza,...  Gazzetta di Modena   \n",
       "17452  [modena, mentre, parlare, indire, inferriata, ...  Gazzetta di Modena   \n",
       "17453  [guardia, finanza, proseguire, lottare, produr...         ModenaToday   \n",
       "17454  [modena, stare, sorteggiare, lettera, alfabeto...  Gazzetta di Modena   \n",
       "\n",
       "             date      time          tag  \n",
       "0      2021-06-25  01:00:00        furto  \n",
       "1      2021-06-24  01:00:00        furto  \n",
       "2      2021-06-24  01:00:00        furto  \n",
       "3      2021-09-01  01:00:00        furto  \n",
       "4      2021-03-08  01:00:00        furto  \n",
       "...           ...       ...          ...  \n",
       "17450  2016-11-14  12:38:00  aggressione  \n",
       "17451  2017-01-31  01:00:00        furto  \n",
       "17452  2020-01-01  01:00:00        furto  \n",
       "17453  2014-09-18  15:02:00    sequestro  \n",
       "17454  2020-06-16  01:00:00        furto  \n",
       "\n",
       "[17455 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(folder+\"/dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get a Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Use a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Download model from https://mlunicampania.gitlab.io/italian-word2vec/\n",
    "\n",
    "pretrained_word_vectors = KeyedVectors.load(\"W2V.kv\", mmap='r+')\n",
    "#pretrained_vocabs = pretrained_word_vectors.index_to_key\n",
    "pretrained_vectors = pretrained_word_vectors.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Train a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def train_model_from_scratch():\n",
    "    w2v_model = Word2Vec(sg=1,\n",
    "                     min_count=20,\n",
    "                     window=10,\n",
    "                     size=300,\n",
    "                     sample=1e-3, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=7)\n",
    "    w2v_model.build_vocab(data['preprocessed'], progress_per=10000)\n",
    "    w2v_model.train(data['preprocessed'], total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "    model_name = folder+\"/models/from_scratch.kv\"\n",
    "    word_vectors = w2v_model.wv\n",
    "    word_vectors.save(model_name)\n",
    "\n",
    "train_model_from_scratch()\n",
    "new_word_vectors = KeyedVectors.load(folder+\"/models/from_scratch.kv\", mmap='r+')\n",
    "#new_vocabs = new_word_vectors.index_to_key\n",
    "new_vectors = new_word_vectors.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Retrain a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\Anaconda3\\envs\\new_env\\lib\\site-packages\\gensim\\models\\word2vec.py:909: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  weights = fromstring(fin.read(binary_len), dtype=REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "def retrain_pretrained_model():\n",
    "    sentences = data['preprocessed'].values.tolist()\n",
    "    w2v_model = Word2Vec(sg=1,\n",
    "                    min_count=20,\n",
    "                    window=10,\n",
    "                    size=300,\n",
    "                    sample=1e-3,\n",
    "                    negative=20,\n",
    "                    workers=7)\n",
    "    w2v_model.build_vocab(sentences)\n",
    "    w2v_model.intersect_word2vec_format(\"W2V.bin\", binary=True, lockf=1.0)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs, report_delay=1)\n",
    "    model_name = folder+\"/models/retrained.kv\"\n",
    "    word_vectors = w2v_model.wv\n",
    "    word_vectors.save(model_name)\n",
    "\n",
    "retrain_pretrained_model()\n",
    "retrained_word_vectors = KeyedVectors.load(folder+\"/models/retrained.kv\", mmap='r+')\n",
    "#retrained_vocabs = retrained_word_vectors.index_to_key\n",
    "retrained_vectors = retrained_word_vectors.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Mean Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Simple Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "\n",
    "    def __init__(self, word_model):\n",
    "        self.word_model = word_model\n",
    "        self.vector_size = word_model.vector_size\n",
    "\n",
    "    def fit(self):  # comply with scikit-learn transformer requirement\n",
    "        return self\n",
    "\n",
    "    def transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        doc_word_vector = self.word_average_list(docs)\n",
    "        return doc_word_vector\n",
    "\n",
    "    def word_average(self, sent):\n",
    "        \"\"\"\n",
    "        Compute average word vector for a single doc/sentence.\n",
    "        :param sent: list of sentence tokens\n",
    "        :return: \n",
    "            mean: float of averaging word vectors\n",
    "        \"\"\"\n",
    "        mean = []\n",
    "        for word in sent:\n",
    "            if word in self.word_model.vocab:\n",
    "                mean.append(self.word_model.get_vector(word))\n",
    "        \n",
    "        \n",
    "        if not mean:  # empty words\n",
    "            # If a text is empty, return a vector of zeros.\n",
    "            logging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "            return np.zeros(self.vector_size)\n",
    "        else:\n",
    "            mean = np.array(mean).mean(axis=0)\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def word_average_list(self, docs):\n",
    "        \"\"\"\n",
    "        Compute average word vector for multiple docs, where docs had been tokenized.\n",
    "        :param docs: list of sentence in list of separated tokens\n",
    "        :return:\n",
    "            array of average word vector in shape (len(docs),)\n",
    "        \"\"\"\n",
    "        return np.vstack([self.word_average(sent) for sent in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Mean weighted by TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "\n",
    "    def __init__(self, word_model):\n",
    "\n",
    "        self.word_model = word_model\n",
    "        self.word_idf_weight = None\n",
    "        self.vector_size = word_model.vector_size\n",
    "\n",
    "    def fit(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        \"\"\"\n",
    "        Fit in a list of docs, which had been preprocessed and tokenized,\n",
    "        such as word bi-grammed, stop-words removed, lemmatized, part of speech filtered.\n",
    "        Then build up a tfidf model to compute each word's idf as its weight.\n",
    "        Noted that tf weight is already involved when constructing average word vectors, and thus omitted.\n",
    "        :param\n",
    "        pre_processed_docs: list of docs, which are tokenized\n",
    "        :return:\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        text_docs = []\n",
    "        for doc in docs:\n",
    "            text_docs.append(\" \".join(doc))\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tfidf.fit(text_docs)  # must be list of text string\n",
    "\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of\n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)  # used as default value for defaultdict\n",
    "        self.word_idf_weight = defaultdict(lambda: max_idf, [(word, tfidf.idf_[i]) for word, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, docs):  # comply with scikit-learn transformer requirement\n",
    "        doc_word_vector = self.word_average_list(docs)\n",
    "        return doc_word_vector\n",
    "\n",
    "\n",
    "    def word_average(self, sent):\n",
    "        \"\"\"\n",
    "        Compute average word vector for a single doc/sentence.\n",
    "        :param sent: list of sentence tokens\n",
    "        :return:\n",
    "            mean: float of averaging word vectors\n",
    "        \"\"\"\n",
    "\n",
    "        mean = []\n",
    "        for word in sent:\n",
    "            if word in self.word_model.vocab:\n",
    "                mean.append(self.word_model.get_vector(word) * self.word_idf_weight[word])  # idf weighted\n",
    "\n",
    "        if len(mean) == 0:  # empty words\n",
    "            # If a text is empty, return a vector of zeros.\n",
    "            logging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "            return np.zeros(self.vector_size)\n",
    "        else:\n",
    "            mean = np.array(mean).mean(axis=0)\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def word_average_list(self, docs):\n",
    "        \"\"\"\n",
    "        Compute average word vector for multiple docs, where docs had been tokenized.\n",
    "        :param docs: list of sentence in list of separated tokens\n",
    "        :return:\n",
    "            array of average word vector in shape (len(docs),)\n",
    "        \"\"\"\n",
    "        return np.vstack([self.word_average(sent) for sent in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute word embeddings and store them on csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_to_csv(word_vectors, mean, lemmatization, bigram, filename):\n",
    "    if mean=='simple':\n",
    "        vectorizer = MeanEmbeddingVectorizer(word_vectors)\n",
    "        vectorizer.fit()\n",
    "        features = vectorizer.transform(data['preprocessed'])\n",
    "    elif mean=='tfidf':\n",
    "        vectorizer = TfidfEmbeddingVectorizer(word_vectors)\n",
    "        vectorizer.fit(data['preprocessed'])\n",
    "        features = vectorizer.transform(data['preprocessed'])\n",
    "    \n",
    "    vectors = pd.DataFrame(data=features)\n",
    "    vectors.insert(0, 'url', data['url'].values)\n",
    "    vectors.insert(1, 'title', data['title'].values)\n",
    "    vectors.insert(2, 'newspaper', data['newspaper'].values)\n",
    "    vectors.insert(3, 'text', data['text'].values)\n",
    "    vectors.insert(4, 'date', data['date'].values)\n",
    "    vectors.insert(5, 'time', data['time'].values)\n",
    "    vectors.insert(6, 'preprocessed', data['preprocessed'].values)\n",
    "    vectors.insert(7, 'target', data['tag'].values)\n",
    "    vectors = vectors.reset_index(drop=True)\n",
    "    \n",
    "    vectors.to_csv(folder+'/'+mean+'/csv/'+filename+'_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(pretrained_word_vectors, 'simple', lemmatization, bigram, 'pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(pretrained_word_vectors, 'tfidf', lemmatization, bigram, 'pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(new_word_vectors, 'simple', lemmatization, bigram, 'new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(new_word_vectors, 'tfidf', lemmatization, bigram, 'new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(retrained_word_vectors, 'simple', lemmatization, bigram, 'retrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectors_to_csv(retrained_word_vectors, 'tfidf', lemmatization, bigram, 'retrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
